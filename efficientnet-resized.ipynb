{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pytorch-ignite==0.2.* tensorboardX==1.6.*\n\nimport os\nimport numpy as np\nimport random\nimport torch\nimport torch.nn as nn\nimport ignite\n\nseed = 17\nrandom.seed(seed)\n_ = torch.manual_seed(seed)\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:07.541579Z","iopub.execute_input":"2023-02-04T12:07:07.542465Z","iopub.status.idle":"2023-02-04T12:07:21.347723Z","shell.execute_reply.started":"2023-02-04T12:07:07.542429Z","shell.execute_reply":"2023-02-04T12:07:21.346679Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting pytorch-ignite==0.2.*\n  Downloading pytorch_ignite-0.2.1-py2.py3-none-any.whl (84 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m919.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting tensorboardX==1.6.*\n  Downloading tensorboardX-1.6-py2.py3-none-any.whl (129 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from pytorch-ignite==0.2.*) (1.11.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from tensorboardX==1.6.*) (1.21.6)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from tensorboardX==1.6.*) (1.15.0)\nRequirement already satisfied: protobuf>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from tensorboardX==1.6.*) (3.19.4)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->pytorch-ignite==0.2.*) (4.3.0)\nInstalling collected packages: tensorboardX, pytorch-ignite\n  Attempting uninstall: tensorboardX\n    Found existing installation: tensorboardX 2.5.1\n    Uninstalling tensorboardX-2.5.1:\n      Successfully uninstalled tensorboardX-2.5.1\n  Attempting uninstall: pytorch-ignite\n    Found existing installation: pytorch-ignite 0.4.10\n    Uninstalling pytorch-ignite-0.4.10:\n      Successfully uninstalled pytorch-ignite-0.4.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncatalyst 22.4 requires tensorboardX>=2.1.0, but you have tensorboardx 1.6 which is incompatible.\nallennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pytorch-ignite-0.2.1 tensorboardX-1.6\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from copy import deepcopy\nimport torch.nn.utils.prune as prune","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:21.352306Z","iopub.execute_input":"2023-02-04T12:07:21.352806Z","iopub.status.idle":"2023-02-04T12:07:21.359236Z","shell.execute_reply.started":"2023-02-04T12:07:21.352776Z","shell.execute_reply":"2023-02-04T12:07:21.358183Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Define model","metadata":{}},{"cell_type":"code","source":"class Swish(nn.Module):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n\n\nclass Flatten(nn.Module):\n    def forward(self, x):\n        return x.reshape(x.shape[0], -1)","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:21.361037Z","iopub.execute_input":"2023-02-04T12:07:21.362127Z","iopub.status.idle":"2023-02-04T12:07:21.369628Z","shell.execute_reply.started":"2023-02-04T12:07:21.362033Z","shell.execute_reply":"2023-02-04T12:07:21.368665Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"without dropout","metadata":{}},{"cell_type":"code","source":"def targeted_dropout(a, w, training, gamma=1, alpha=0.5):\n    '''таргетированный дропаут\n    a - активности на выходе слоя, layer size: Batch * Cout * H * W\n    w - веса конволюционного слоя, conv weight size: Cout * Cin * k * k\n    gamma - доля выходных каналов, подверженных дропауту  (от 0 до 1)\n    alpha - величина отсева дропаута (от 0 до 1)\n    '''\n    # считаем норму весов для каждого выходного канала\n    with torch.no_grad():\n        norms = torch.norm(w.reshape(w.shape[0], -1), dim=1)\n        C_out = len(norms) # количество выходных каналов\n        values, indexes = torch.sort(norms)\n        changed = indexes[:int(gamma * C_out)]\n    #применяем дропаут только к выбранным gamma * C_out каналам\n    a[:, changed] = F.dropout2d(a[:, changed], alpha, training=training)\n    return a","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:21.371187Z","iopub.execute_input":"2023-02-04T12:07:21.371545Z","iopub.status.idle":"2023-02-04T12:07:21.386839Z","shell.execute_reply.started":"2023-02-04T12:07:21.371498Z","shell.execute_reply":"2023-02-04T12:07:21.385823Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class SqueezeExcitation(nn.Module):\n    \n    def __init__(self, inplanes, se_planes, gamma=1, alpha=0.5):\n        super(SqueezeExcitation, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, se_planes, \n                      kernel_size=1, stride=1, padding=0, bias=False)\n        self.conv2 = nn.Conv2d(se_planes, inplanes, \n                      kernel_size=1, stride=1, padding=0, bias=False)\n        self.swish = Swish()\n        self.sigmoid = nn.Sigmoid()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.in_mask = None\n        self.out_mask = None\n        self.coeff = 1\n\n    def forward(self, x):\n        x_se = torch.mean(x, dim=(-2, -1), keepdim=True) #* self.coeff\n        x_se = self.conv1(x_se)\n        x_se = targeted_dropout(x_se, self.conv1.weight, self.training, self.gamma, self.alpha)\n        x_se = self.swish(x_se)\n        x_se = self.conv2(x_se)\n        x_se = targeted_dropout(x_se, self.conv2.weight, self.training, self.gamma, self.alpha)\n        x_se = self.sigmoid(x_se)\n        if self.out_mask is not None:\n#             x_full = torch.zeros((x.size()[0], len(self.in_mask), x.size()[2], x.size()[3]), device=device)\n#             x_full[:, self.in_mask, :, :] = x\n#             x_se_full = torch.zeros((x_se.size()[0], len(self.out_mask), x_se.size()[2], x_se.size()[3]), device=device)\n#             x_se_full[:, self.out_mask, :, :] = x_se\n#             return (x_se_full * x_full)[:, self.out_mask]\n\n            mask_mult = self.in_mask * self.out_mask\n            in_mask = mask_mult[self.in_mask]\n            out_mask = mask_mult[self.out_mask]\n            x[:, ~in_mask] = 0\n            x[:, in_mask] = x_se[:, out_mask] * x[:, in_mask]\n            return x\n        else:\n            return x_se * x\n","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:21.388470Z","iopub.execute_input":"2023-02-04T12:07:21.388895Z","iopub.status.idle":"2023-02-04T12:07:21.402388Z","shell.execute_reply.started":"2023-02-04T12:07:21.388860Z","shell.execute_reply":"2023-02-04T12:07:21.401527Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class DepthWiseConv(nn.Module):\n    \n    def __init__(self, inplanes, expand_planes, kernel_size, stride, gamma=1, alpha=0.5):\n        super(DepthWiseConv, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.conv = nn.Conv2d(inplanes, expand_planes,\n                      kernel_size=kernel_size, stride=stride, \n                      padding=kernel_size // 2, groups=expand_planes,\n                      bias=False)\n        self.bn = nn.BatchNorm2d(expand_planes, momentum=0.01, eps=1e-3)\n        self.swish = Swish()\n        \n    def forward(self, x):\n        \n        x = self.conv(x)\n        x = self.bn(x)\n        x = targeted_dropout(x, self.conv.weight, self.training, self.gamma, self.alpha)\n        x = self.swish(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:21.403504Z","iopub.execute_input":"2023-02-04T12:07:21.403776Z","iopub.status.idle":"2023-02-04T12:07:21.417816Z","shell.execute_reply.started":"2023-02-04T12:07:21.403751Z","shell.execute_reply":"2023-02-04T12:07:21.416939Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class ProjectConv(nn.Module):\n    \n    def __init__(self, expand_planes, planes, gamma=1, alpha=0.5):\n        super(ProjectConv, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.conv = nn.Conv2d(expand_planes, planes, \n                      kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn = nn.BatchNorm2d(planes, momentum=0.01, eps=1e-3)\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = targeted_dropout(x, self.conv.weight, self.training, self.gamma, self.alpha)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:21.419357Z","iopub.execute_input":"2023-02-04T12:07:21.419937Z","iopub.status.idle":"2023-02-04T12:07:21.431017Z","shell.execute_reply.started":"2023-02-04T12:07:21.419900Z","shell.execute_reply":"2023-02-04T12:07:21.430015Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class ExpansionConv(nn.Module):\n    \n    def __init__(self, inplanes, expand_planes, gamma=1, alpha=0.5):\n        super(ExpansionConv, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.conv = nn.Conv2d(inplanes, expand_planes, \n                      kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn = nn.BatchNorm2d(expand_planes, momentum=0.01, eps=1e-3)\n        self.swish = Swish()\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = targeted_dropout(x, self.conv.weight, self.training, self.gamma, self.alpha)\n        x = self.swish(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:21.435683Z","iopub.execute_input":"2023-02-04T12:07:21.435935Z","iopub.status.idle":"2023-02-04T12:07:21.444596Z","shell.execute_reply.started":"2023-02-04T12:07:21.435912Z","shell.execute_reply":"2023-02-04T12:07:21.443459Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from torch.nn import functional as F\n\nclass MBConv(nn.Module):\n    def __init__(self, inplanes, planes, kernel_size, stride, \n                 expand_rate=1.0, se_rate=0.25, \n                 drop_connect_rate=0.2, \n                 gamma=1, \n                 alpha=0.5\n                ):\n        super(MBConv, self).__init__()\n\n        expand_planes = int(inplanes * expand_rate)\n        se_planes = max(1, int(inplanes * se_rate))\n\n        self.expansion_conv = None        \n        if expand_rate > 1.0:\n            self.expansion_conv = ExpansionConv(inplanes, expand_planes, gamma=gamma, alpha=alpha)\n            inplanes = expand_planes\n\n        self.depthwise_conv = DepthWiseConv(inplanes, expand_planes, kernel_size,\n                                            stride, gamma=gamma, alpha=alpha)\n\n        self.squeeze_excitation = SqueezeExcitation(expand_planes, se_planes, \n                                                    gamma=gamma, alpha=alpha)\n        \n        self.project_conv = ProjectConv(expand_planes, planes, gamma=gamma, alpha=alpha)\n\n        self.with_skip = stride == 1\n        self.drop_connect_rate = torch.tensor(drop_connect_rate, requires_grad=False)\n        self.in_mask = None\n        self.out_mask = None\n    \n    def _drop_connect(self, x):        \n        keep_prob = 1.0 - self.drop_connect_rate\n        drop_mask = torch.rand(x.shape[0], 1, 1, 1) + keep_prob\n        drop_mask = drop_mask.type_as(x)\n        drop_mask.floor_()\n        return drop_mask * x / keep_prob\n        \n    def forward(self, x):\n        z = x\n        if self.expansion_conv is not None:\n            x = self.expansion_conv(x)\n\n        x = self.depthwise_conv(x)\n        x = self.squeeze_excitation(x)\n        x = self.project_conv(x)\n        \n        # Add identity skip\n      \n        if x.shape == z.shape and self.with_skip:  \n            if self.training and self.drop_connect_rate is not None:\n                self._drop_connect(x)\n            if self.out_mask is not None:\n#                 x_full = torch.zeros((x.size()[0], len(self.in_mask), x.size()[2], x.size()[3]), device=device)\n#                 x_full[:, self.in_mask, :, :] = x\n#                 x_se_full = torch.zeros((x_se.size()[0], len(self.out_mask), x_se.size()[2], x_se.size()[3]), device=device)\n#                 x_se_full[:, self.out_mask, :, :] = x_se\n#                 x = (x_se_full * x_full)[:, self.out_mask]\n                mask_mult = self.in_mask * self.out_mask\n                in_mask = mask_mult[self.in_mask]\n                out_mask = mask_mult[self.out_mask]\n                x[:, out_mask] = x[:, out_mask] + z[:, in_mask]\n            else:\n                x += z\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:21.446338Z","iopub.execute_input":"2023-02-04T12:07:21.446727Z","iopub.status.idle":"2023-02-04T12:07:21.461020Z","shell.execute_reply.started":"2023-02-04T12:07:21.446646Z","shell.execute_reply":"2023-02-04T12:07:21.460218Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class Stem(nn.Module):\n    \n    def __init__(self, list_channels, gamma=1, alpha=0.5):\n        super(Stem, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.conv = nn.Conv2d(3, list_channels[0], kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn = nn.BatchNorm2d(list_channels[0], momentum=0.01, eps=1e-3)\n        self.swish = Swish()\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = targeted_dropout(x, self.conv.weight, self.training, self.gamma, self.alpha)\n        x = self.swish(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:21.462035Z","iopub.execute_input":"2023-02-04T12:07:21.463024Z","iopub.status.idle":"2023-02-04T12:07:21.476963Z","shell.execute_reply.started":"2023-02-04T12:07:21.462979Z","shell.execute_reply":"2023-02-04T12:07:21.476047Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class HeadModule(nn.Module):\n    \n    def __init__(self, list_channels, num_classes, gamma=1, alpha=0.5):\n        super(HeadModule, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.conv = nn.Conv2d(list_channels[-2], list_channels[-1], \n                      kernel_size=1, bias=False)\n        self.bn = nn.BatchNorm2d(list_channels[-1], momentum=0.01, eps=1e-3)\n        self.swish = Swish()\n        self.avg = nn.AdaptiveAvgPool2d(1)\n        self.flatten = Flatten()\n        self.linear = nn.Linear(list_channels[-1], num_classes)\n        self.coeff = 1\n\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = targeted_dropout(x, self.conv.weight, self.training, self.gamma, self.alpha)\n        x = self.swish(x)\n        x = self.avg(x) \n        x = self.flatten(x)\n        x = self.linear(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:21.478245Z","iopub.execute_input":"2023-02-04T12:07:21.478646Z","iopub.status.idle":"2023-02-04T12:07:21.488546Z","shell.execute_reply.started":"2023-02-04T12:07:21.478612Z","shell.execute_reply":"2023-02-04T12:07:21.487590Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"from collections import OrderedDict\nimport math\n\n\ndef init_weights(module):    \n    if isinstance(module, nn.Conv2d):    \n        nn.init.kaiming_normal_(module.weight, a=0, mode='fan_out')\n    elif isinstance(module, nn.Linear):\n        init_range = 1.0 / math.sqrt(module.weight.shape[1])\n        nn.init.uniform_(module.weight, a=-init_range, b=init_range)\n        \n        \nclass EfficientNet(nn.Module):\n        \n    def _setup_repeats(self, num_repeats):\n        return int(math.ceil(self.depth_coefficient * num_repeats))\n    \n    def _setup_channels(self, num_channels):\n        num_channels *= self.width_coefficient\n        new_num_channels = math.floor(num_channels / self.divisor + 0.5) * self.divisor\n        new_num_channels = max(self.divisor, new_num_channels)\n        if new_num_channels < 0.9 * num_channels:\n            new_num_channels += self.divisor\n        return new_num_channels\n\n    def __init__(self, num_classes=10, \n                 width_coefficient=1.0,\n                 depth_coefficient=1.0,\n                 se_rate=0.25,\n                 gamma=1, alpha=0.5,\n                 drop_connect_rate=0.2):\n        super(EfficientNet, self).__init__()\n        \n        self.width_coefficient = width_coefficient\n        self.depth_coefficient = depth_coefficient\n        self.divisor = 8\n                \n        list_channels = [32, 16, 24, 40, 80, 112, 192, 320, 1280]\n        list_channels = [self._setup_channels(c) for c in list_channels]\n                \n        list_num_repeats = [1, 2, 2, 3, 3, 4, 1]\n        list_num_repeats = [self._setup_repeats(r) for r in list_num_repeats]        \n        \n        expand_rates = [1, 6, 6, 6, 6, 6, 6]\n        strides = [1, 2, 2, 2, 1, 2, 1]\n        kernel_sizes = [3, 3, 5, 3, 5, 5, 3]\n\n        # Define stem:\n        self.stem = Stem(list_channels, gamma=gamma, alpha=alpha)\n        \n        # Define MBConv blocks\n        blocks = []\n        counter = 0\n        num_blocks = sum(list_num_repeats)\n        for idx in range(7):\n            \n            num_channels = list_channels[idx]\n            next_num_channels = list_channels[idx + 1]\n            num_repeats = list_num_repeats[idx]\n            expand_rate = expand_rates[idx]\n            kernel_size = kernel_sizes[idx]\n            stride = strides[idx]\n            drop_rate = drop_connect_rate * counter / num_blocks\n            \n            name = \"MBConv{}_{}\".format(expand_rate, counter)\n            blocks.append((\n                name,\n                MBConv(num_channels, next_num_channels, \n                       kernel_size=kernel_size, stride=stride, expand_rate=expand_rate, \n                       se_rate=se_rate, drop_connect_rate=drop_rate, gamma=gamma, alpha=alpha)\n            ))\n            counter += 1\n            for i in range(1, num_repeats):                \n                name = \"MBConv{}_{}\".format(expand_rate, counter)\n                drop_rate = drop_connect_rate * counter / num_blocks                \n                blocks.append((\n                    name,\n                    MBConv(next_num_channels, next_num_channels, \n                           kernel_size=kernel_size, stride=1, expand_rate=expand_rate, \n                           se_rate=se_rate, drop_connect_rate=drop_rate, gamma=gamma, alpha=alpha)                                    \n                ))\n                counter += 1\n        \n        self.blocks = nn.Sequential(OrderedDict(blocks))\n        \n        # Define head\n        self.head = HeadModule(list_channels, num_classes, gamma=gamma, alpha=alpha)\n\n        self.apply(init_weights)\n        \n    def forward(self, x):\n        f = self.stem(x)\n        f = self.blocks(f)\n        y = self.head(f)\n        return y","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:21.490124Z","iopub.execute_input":"2023-02-04T12:07:21.490600Z","iopub.status.idle":"2023-02-04T12:07:21.510657Z","shell.execute_reply.started":"2023-02-04T12:07:21.490562Z","shell.execute_reply":"2023-02-04T12:07:21.509929Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Load model","metadata":{}},{"cell_type":"code","source":"model3 = EfficientNet(gamma=0.6, alpha=0.5)\nmodel3.load_state_dict(torch.load('../input/efficientnet-cifar/efficientNet_cifar_0.6_0.5.pth',\n                      map_location=torch.device(device)))","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:38.999925Z","iopub.execute_input":"2023-02-04T12:07:39.000304Z","iopub.status.idle":"2023-02-04T12:07:42.240185Z","shell.execute_reply.started":"2023-02-04T12:07:39.000271Z","shell.execute_reply":"2023-02-04T12:07:42.239158Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"model1 = EfficientNet(dropout_rate=0)\nmodel1.load_state_dict(torch.load('../input/efficientnet-cifar/efficientNet_drop_0.pth'))","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:21.661757Z","iopub.status.idle":"2023-02-04T12:07:21.662490Z","shell.execute_reply.started":"2023-02-04T12:07:21.662231Z","shell.execute_reply":"2023-02-04T12:07:21.662256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model2 = EfficientNet(dropout_rate=0.2)\nmodel2.load_state_dict(torch.load('../input/efficientnet-cifar/efficientnet_drop_2.pth'))","metadata":{"execution":{"iopub.status.busy":"2023-01-13T09:03:02.907930Z","iopub.status.idle":"2023-01-13T09:03:02.908278Z","shell.execute_reply.started":"2023-01-13T09:03:02.908113Z","shell.execute_reply":"2023-01-13T09:03:02.908130Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pruning and resizing","metadata":{}},{"cell_type":"code","source":"def change_layer(net, layer_resized, layer_type, name):\n    tokens = name.strip().split('.')\n    layer = net\n    for t in tokens[:-1]:\n        if not t.isnumeric():\n            layer = getattr(layer, t)\n        else:\n            layer = layer[int(t)]\n    setattr(layer, tokens[-1], layer_resized)","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:45.627766Z","iopub.execute_input":"2023-02-04T12:07:45.628153Z","iopub.status.idle":"2023-02-04T12:07:45.635053Z","shell.execute_reply.started":"2023-02-04T12:07:45.628115Z","shell.execute_reply":"2023-02-04T12:07:45.634135Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def get_pruned_model(model, normed=False, amount=0.5):\n    model_pruned = deepcopy(model)\n    for key, layer in model_pruned.named_modules():\n        # remove pruning from last layer\n        if isinstance(layer, nn.Conv2d):\n            prune.ln_structured(layer, name='weight', amount=amount, n=2, dim=0)\n            if normed:\n                layer.weight = layer.weight / (1 - amount)\n    return model_pruned\n\n\ndef remove_prune_params(model):\n    for key, value in model.named_modules():\n        if isinstance(value, nn.Conv2d):\n            prune.remove(value, name='weight')\n        elif isinstance(value, nn.Linear):\n            prune.remove(value, name='weight')\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:45.980804Z","iopub.execute_input":"2023-02-04T12:07:45.981493Z","iopub.status.idle":"2023-02-04T12:07:45.988695Z","shell.execute_reply.started":"2023-02-04T12:07:45.981455Z","shell.execute_reply":"2023-02-04T12:07:45.987682Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def change_conv_weights_in(layer, in_mask=None, coeff=None):\n    copy_weight = layer.weight\n#     if coeff is not None:\n#         copy_weight = copy_weight * (1 - coeff)\n    copy_bias = layer.bias\n    out_channels = layer.out_channels \n    out_mask = np.array([True] * out_channels)\n    in_channels = len(np.where(in_mask == True)[0])\n    kernel_size = layer.kernel_size\n    stride = layer.stride\n    padding = layer.padding\n    \n    if layer.groups != 1:\n        groups = in_channels\n        out_mask = out_mask * in_mask\n        in_mask = [True]\n    else:\n        groups = 1\n        \n    is_bias = False if copy_bias is None else True\n    layer = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, \n                      stride=stride, padding=padding, bias=is_bias, groups=groups)\n#     print('after', in_channels, out_channels, copy_weight.shape, in_mask.shape)\n    with torch.no_grad():\n        layer.weight.copy_(copy_weight[out_mask][:, in_mask])\n        if copy_bias is not None:\n            layer.bias.copy_(copy_bias)\n    return layer, out_mask\n\ndef change_conv_weights_out(layer, out_mask):\n    copy_weight = layer.weight\n    copy_bias = layer.bias\n    out_channels = len(np.where(out_mask == True)[0])\n    in_channels = layer.in_channels \n    kernel_size = layer.kernel_size\n    stride = layer.stride\n    padding = layer.padding\n    groups = 1\n    is_bias = False if copy_bias is None else True\n    layer = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, \n                      stride=stride, padding=padding, bias=is_bias, groups=groups)\n    with torch.no_grad():\n        layer.weight.copy_(copy_weight[out_mask])\n        if copy_bias is not None:\n            layer.bias.copy_(copy_bias[out_mask])\n    return layer\n\ndef change_conv_weights(layer, in_mask=None, coeff=None, ):\n    copy_weight = layer.weight\n    if coeff is not None:\n        copy_weight = copy_weight * (1 - coeff)\n    copy_bias = layer.bias\n    out_mask = layer.weight_mask.detach().cpu().numpy()[:, 0, 0, 0] == 1\n    in_channels = len(np.where(in_mask == True)[0])\n    out_channels = len(np.where(out_mask == True)[0])\n    kernel_size = layer.kernel_size\n    stride = layer.stride\n    padding = layer.padding\n    out_mask_prev_layer = None\n    if layer.groups != 1:\n        out_mask_prev_layer = out_mask[in_mask]\n        out_mask = out_mask * in_mask\n        out_channels = len(np.where(out_mask == True)[0])\n        groups = out_channels\n        in_channels = out_channels\n        in_mask = [True]\n    else:\n        groups = 1\n    is_bias = False if copy_bias is None else True\n    layer = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, \n                      stride=stride, padding=padding, bias=is_bias, groups=groups)\n    with torch.no_grad():\n        layer.weight.copy_(copy_weight[out_mask][:, in_mask])\n        if copy_bias is not None:\n            layer.bias.copy_(copy_bias[out_mask])\n    return layer, out_mask, out_mask_prev_layer\n\ndef change_lin_weights(layer, in_mask):\n    copy_weight = layer.weight\n    copy_bias = layer.bias\n    hw = int(layer.in_features / len(in_mask))\n    in_mask = np.repeat(in_mask, hw)\n    in_features = len(np.where(in_mask == True)[0])    \n    out_features = layer.out_features\n    is_bias = False if copy_bias is None else True\n    layer = nn.Linear(in_features, out_features, bias=is_bias)\n    with torch.no_grad():\n        layer.weight.copy_(copy_weight[:, in_mask])\n        if copy_bias is not None:\n            layer.bias.copy_(copy_bias)\n    return layer\n\ndef change_bn(layer, in_mask, prune_rate=None, norm_mean_var=False):\n    if norm_mean_var:\n        copy_mean = layer.running_mean * (1 - prune_rate)\n        copy_var = layer.running_var * (1 - prune_rate)\n    else:\n        copy_mean = layer.running_mean\n        copy_var = layer.running_var\n    copy_weight = layer.weight\n    copy_bias = layer.bias\n    eps = layer.eps\n    momentum = layer.momentum\n    affine = layer.affine\n    track_running_stats = layer.track_running_stats\n    \n    channels = len(np.where(in_mask == True)[0])\n    if isinstance(layer, torch.nn.BatchNorm2d):\n        layer = nn.BatchNorm2d(channels, eps=eps, momentum=momentum, \n                               affine=affine, track_running_stats=track_running_stats)\n    else:\n        layer = nn.BatchNorm1d(channels, eps=eps, momentum=momentum, \n                               affine=affine, track_running_stats=track_running_stats)\n    with torch.no_grad():\n        layer.weight.copy_(copy_weight[in_mask])\n        layer.bias.copy_(copy_bias[in_mask])\n        layer.running_mean.copy_(copy_mean[in_mask])\n        layer.running_var.copy_(copy_var[in_mask])\n    return layer\n\ndef change_bn_out(layer, in_mask):\n    copy_mean = layer.running_mean\n    copy_var = layer.running_var\n    copy_weight = layer.weight\n    copy_bias = layer.bias\n    eps = layer.eps\n    momentum = layer.momentum\n    affine = layer.affine\n    track_running_stats = layer.track_running_stats\n    \n    channels = len(np.where(in_mask == True)[0])\n    if isinstance(layer, torch.nn.BatchNorm2d):\n        layer = nn.BatchNorm2d(channels, eps=eps, momentum=momentum, \n                               affine=affine, track_running_stats=track_running_stats)\n    else:\n        layer = nn.BatchNorm1d(channels, eps=eps, momentum=momentum, \n                               affine=affine, track_running_stats=track_running_stats)\n    with torch.no_grad():\n        layer.weight.copy_(copy_weight[in_mask])\n        layer.bias.copy_(copy_bias[in_mask])\n        layer.running_mean.copy_(copy_mean[in_mask])\n        layer.running_var.copy_(copy_var[in_mask])\n    return layer\n\ndef resize_model(model, device, prune_rate, norm_mean_var=True):\n    model = model.cpu()\n    in_mask = np.array([True] * 3) \n    to_change = True\n    # define prune rate by first conv layer\n    change_in = False\n    is_depthwise = False\n    is_squeeze = False\n    is_proj_conv = False\n    out_masks = []\n    for key, layer in model.named_modules():\n        if isinstance(layer, MBConv):\n            layer.in_mask = in_mask\n            layer_mb = layer\n        elif isinstance(layer, ProjectConv):\n            is_proj_conv = True\n        elif isinstance(layer, SqueezeExcitation):\n            layer.coeff = prune_rate\n            layer.in_mask = in_mask\n            layer_squeeze = layer\n            is_squeeze = True\n        elif isinstance(layer, HeadModule):\n            layer.coeff = prune_rate\n        elif isinstance(layer, torch.nn.Conv2d):\n            out_channels = layer.out_channels\n#             if to_change:\n            layer_resized, out_mask, out_mask_prev_layer = change_conv_weights(layer, in_mask)\n            change_layer(model, layer_resized, torch.nn.Conv2d, key)\n            in_mask = out_mask\n            if out_mask_prev_layer is not None:\n                out_masks.append(out_mask_prev_layer)\n            if is_proj_conv:\n                layer_mb.out_mask = in_mask\n                is_proj_conv = False\n        elif is_squeeze and isinstance(layer, nn.Sigmoid):\n            is_squeeze = False\n            layer_squeeze.out_mask = out_mask\n            in_mask = layer_squeeze.in_mask \n        elif isinstance(layer, torch.nn.Linear):\n            layer_resized = change_lin_weights(layer, in_mask)\n#             if to_change:\n            change_layer(model, layer_resized, torch.nn.Linear, key)\n        elif (isinstance(layer, torch.nn.BatchNorm2d) or \\\n            isinstance(layer, torch.nn.BatchNorm1d)):\n            layer_resized = change_bn(layer, in_mask, prune_rate, norm_mean_var)\n            change_layer(model, layer_resized, torch.nn.BatchNorm2d, key)\n    return model.to(device), out_masks\n            \ndef tune_layer_before_depthwise(model, out_masks): \n    is_depthwise = False\n    module_list = {}\n    for key, layer in model.named_modules():\n        if not isinstance(layer, MBConv) or isinstance(layer, nn.Sequential) or\\\n            isinstance(layer, EfficientNet):\n            module_list[key] = layer\n            \n    module_list_inv = {k: module_list[k] for k in list(module_list.keys())[::-1]}\n    out_masks_inv = out_masks[::-1]\n    i = 0\n    for key, layer in module_list_inv.items():\n        if isinstance(layer, DepthWiseConv):\n            is_depthwise = True\n            out_mask = out_masks_inv[i]\n        if isinstance(layer, torch.nn.Conv2d) and is_depthwise:\n            layer_resized = change_conv_weights_out(layer, out_mask)\n            change_layer(model, layer_resized, torch.nn.Conv2d, key)\n            is_depthwise = False\n        elif (isinstance(layer, torch.nn.BatchNorm2d)) and is_depthwise:\n            layer_resized = change_bn_out(layer, out_mask)\n            change_layer(model, layer_resized, torch.nn.BatchNorm2d, key)\n            i += 1\n    return model.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:07:46.495142Z","iopub.execute_input":"2023-02-04T12:07:46.495538Z","iopub.status.idle":"2023-02-04T12:07:46.533207Z","shell.execute_reply.started":"2023-02-04T12:07:46.495497Z","shell.execute_reply":"2023-02-04T12:07:46.532031Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# model = deepcopy(model1)\nmodel = deepcopy(model3)\namount = 0.4\npruned_model = get_pruned_model(model, amount=amount)\nresized_model, out_masks =\\\n        resize_model(pruned_model, device=device, prune_rate=amount)\nresized_model = tune_layer_before_depthwise(resized_model, out_masks)\npruned_model = get_pruned_model(model, amount=amount)\nmodel = deepcopy(model3)","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:14:41.055078Z","iopub.execute_input":"2023-02-04T12:14:41.055570Z","iopub.status.idle":"2023-02-04T12:14:41.678857Z","shell.execute_reply.started":"2023-02-04T12:14:41.055530Z","shell.execute_reply":"2023-02-04T12:14:41.677819Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## Data flow","metadata":{}},{"cell_type":"code","source":"from torchvision.datasets.cifar import CIFAR100, CIFAR10\nfrom torchvision.transforms import Compose, RandomCrop, Pad, RandomHorizontalFlip, Resize, RandomAffine\nfrom torchvision.transforms import ToTensor, Normalize\n\nfrom torch.utils.data import Subset\nimport torchvision.utils as vutils","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:14:52.438386Z","iopub.execute_input":"2023-02-04T12:14:52.438864Z","iopub.status.idle":"2023-02-04T12:14:52.447128Z","shell.execute_reply.started":"2023-02-04T12:14:52.438822Z","shell.execute_reply":"2023-02-04T12:14:52.446145Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"!ls ../input\n!tar -zxvf ../input/cifar10-python/cifar-10-python.tar.gz","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:14:52.749323Z","iopub.execute_input":"2023-02-04T12:14:52.749997Z","iopub.status.idle":"2023-02-04T12:14:56.811709Z","shell.execute_reply.started":"2023-02-04T12:14:52.749960Z","shell.execute_reply":"2023-02-04T12:14:56.810415Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"cifar10-python\tefficientnet-cifar\ncifar-10-batches-py/\ncifar-10-batches-py/data_batch_4\ncifar-10-batches-py/readme.html\ncifar-10-batches-py/test_batch\ncifar-10-batches-py/data_batch_3\ncifar-10-batches-py/batches.meta\ncifar-10-batches-py/data_batch_2\ncifar-10-batches-py/data_batch_5\ncifar-10-batches-py/data_batch_1\n","output_type":"stream"}]},{"cell_type":"code","source":"from PIL.Image import BICUBIC\n\npath = \".\"\nimage_size = 224\n\ntrain_transform = Compose([\n    Resize(image_size, BICUBIC),\n    RandomAffine(degrees=2, translate=(0.02, 0.02), scale=(0.98, 1.02), shear=2, fillcolor=(124,117,104)),\n    RandomHorizontalFlip(),\n    ToTensor(),\n    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = Compose([\n    Resize(image_size, BICUBIC),    \n    ToTensor(),\n    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_dataset = CIFAR10(root=path, train=True, transform=train_transform, download=False)\ntest_dataset = CIFAR10(root=path, train=False, transform=test_transform, download=False)\n\ntrain_eval_indices = [random.randint(0, len(train_dataset) - 1) for i in range(len(test_dataset))]\ntrain_eval_dataset = Subset(train_dataset, train_eval_indices)\n\nlen(train_dataset), len(test_dataset), len(train_eval_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:14:56.815638Z","iopub.execute_input":"2023-02-04T12:14:56.816353Z","iopub.status.idle":"2023-02-04T12:14:57.849109Z","shell.execute_reply.started":"2023-02-04T12:14:56.816304Z","shell.execute_reply":"2023-02-04T12:14:57.848072Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n  \"\"\"Entry point for launching an IPython kernel.\n","output_type":"stream"},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"(50000, 10000, 10000)"},"metadata":{}}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 125\nnum_workers = 2\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, \n                          shuffle=True, drop_last=True, pin_memory=True)\n\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, \n                         shuffle=False, drop_last=False, pin_memory=True)\n\neval_train_loader = DataLoader(train_eval_dataset, batch_size=batch_size, num_workers=num_workers, \n                               shuffle=False, drop_last=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:14:57.850663Z","iopub.execute_input":"2023-02-04T12:14:57.851061Z","iopub.status.idle":"2023-02-04T12:14:57.858829Z","shell.execute_reply.started":"2023-02-04T12:14:57.851024Z","shell.execute_reply":"2023-02-04T12:14:57.857580Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"print(sum(p.numel() for p in model.parameters()))","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:14:57.862087Z","iopub.execute_input":"2023-02-04T12:14:57.862473Z","iopub.status.idle":"2023-02-04T12:14:57.871488Z","shell.execute_reply.started":"2023-02-04T12:14:57.862436Z","shell.execute_reply":"2023-02-04T12:14:57.870311Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"4011018\n","output_type":"stream"}]},{"cell_type":"code","source":"print(sum(p.numel() for p in pruned_model.parameters()))","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:14:57.873118Z","iopub.execute_input":"2023-02-04T12:14:57.873718Z","iopub.status.idle":"2023-02-04T12:14:57.883700Z","shell.execute_reply.started":"2023-02-04T12:14:57.873683Z","shell.execute_reply":"2023-02-04T12:14:57.882477Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"4011018\n","output_type":"stream"}]},{"cell_type":"code","source":"print(sum(p.numel() for p in resized_model.parameters()))","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:14:57.885834Z","iopub.execute_input":"2023-02-04T12:14:57.886248Z","iopub.status.idle":"2023-02-04T12:14:57.895919Z","shell.execute_reply.started":"2023-02-04T12:14:57.886169Z","shell.execute_reply":"2023-02-04T12:14:57.894765Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"936136\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"from ignite.engine import Engine, Events, create_supervised_evaluator\nfrom ignite.metrics import RunningAverage, Accuracy, Precision, Recall, Loss, TopKCategoricalAccuracy\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:14:57.897769Z","iopub.execute_input":"2023-02-04T12:14:57.898159Z","iopub.status.idle":"2023-02-04T12:14:57.906286Z","shell.execute_reply.started":"2023-02-04T12:14:57.898123Z","shell.execute_reply":"2023-02-04T12:14:57.905087Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"metrics = {\n    'Loss': Loss(criterion),\n    'Accuracy': Accuracy(),\n    'Precision': Precision(average=True),\n    'Recall': Recall(average=True),\n    'Top-5 Accuracy': TopKCategoricalAccuracy(k=5)\n}\nall_pred = np.empty((0, 10), float)\nevaluator = create_supervised_evaluator(model, metrics=metrics, device=device, non_blocking=True)\ntrain_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device, non_blocking=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:14:57.907460Z","iopub.execute_input":"2023-02-04T12:14:57.907744Z","iopub.status.idle":"2023-02-04T12:14:57.937136Z","shell.execute_reply.started":"2023-02-04T12:14:57.907705Z","shell.execute_reply":"2023-02-04T12:14:57.936248Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"evaluator.run(test_loader)","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:14:57.938400Z","iopub.execute_input":"2023-02-04T12:14:57.939296Z","iopub.status.idle":"2023-02-04T12:15:20.691225Z","shell.execute_reply.started":"2023-02-04T12:14:57.939261Z","shell.execute_reply":"2023-02-04T12:15:20.690130Z"},"trusted":true},"execution_count":48,"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"<ignite.engine.engine.State at 0x7ff85d30c890>"},"metadata":{}}]},{"cell_type":"code","source":"# # model = deepcopy(model1)\n# model = deepcopy(model3)\n# amount = 0.4\n# pruned_model = get_pruned_model(model, amount=amount)\n# resized_model, out_masks =\\\n#         resize_model(pruned_model, device=device, prune_rate=amount)\n# resized_model = tune_layer_before_depthwise(resized_model, out_masks)\n# pruned_model = get_pruned_model(model, amount=amount)\n# model = deepcopy(model3)","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:15:20.695061Z","iopub.execute_input":"2023-02-04T12:15:20.695412Z","iopub.status.idle":"2023-02-04T12:15:20.701355Z","shell.execute_reply.started":"2023-02-04T12:15:20.695377Z","shell.execute_reply":"2023-02-04T12:15:20.700188Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# best_model = model.cuda()\nbest_model = pruned_model.cuda()\n# best_model = resized_model.cuda()\ndef inference_update_with_tta(engine, batch):\n    global all_pred\n    best_model.eval()\n    with torch.no_grad():\n        x, y = batch\n        x = x.cuda()   \n        y = y.cuda()    \n        \n        # Let's compute final prediction as a mean of predictions on x and flipped x\n        y_pred1 = best_model(x)\n        y_pred2 = best_model(x.flip(dims=(-1, )))\n        y_pred = 0.5 * (y_pred1 + y_pred2)\n        # calc softmax for submission\n        curr_pred = (0.5 * (F.softmax(y_pred1, dim=-1) + F.softmax(y_pred1, dim=-1))).data.cpu().numpy()\n        all_pred = np.vstack([all_pred, curr_pred])\n\n        return y_pred, y\n\ninferencer = Engine(inference_update_with_tta)\n\nfor name, metric in metrics.items():\n    metric.attach(inferencer, name)","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:15:20.702935Z","iopub.execute_input":"2023-02-04T12:15:20.704008Z","iopub.status.idle":"2023-02-04T12:15:20.723662Z","shell.execute_reply.started":"2023-02-04T12:15:20.703961Z","shell.execute_reply":"2023-02-04T12:15:20.722649Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"## Init","metadata":{}},{"cell_type":"code","source":"result_state = inferencer.run(test_loader, max_epochs=1)\nresult_state.metrics","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:15:20.726160Z","iopub.execute_input":"2023-02-04T12:15:20.726716Z","iopub.status.idle":"2023-02-04T12:15:45.664809Z","shell.execute_reply.started":"2023-02-04T12:15:20.726680Z","shell.execute_reply":"2023-02-04T12:15:45.663745Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"{'Loss': 1.323576310276985,\n 'Accuracy': 0.6474,\n 'Precision': 0.7075708401746205,\n 'Recall': 0.6474,\n 'Top-5 Accuracy': 0.9675}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Pruned","metadata":{}},{"cell_type":"code","source":"result_state = inferencer.run(test_loader, max_epochs=1)\nresult_state.metrics","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:09:28.502884Z","iopub.execute_input":"2023-02-04T12:09:28.503300Z","iopub.status.idle":"2023-02-04T12:09:53.591614Z","shell.execute_reply.started":"2023-02-04T12:09:28.503265Z","shell.execute_reply":"2023-02-04T12:09:53.590611Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"{'Loss': 3.1244347035884856,\n 'Accuracy': 0.1358,\n 'Precision': 0.331027561279032,\n 'Recall': 0.13579999999999998,\n 'Top-5 Accuracy': 0.7887}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Resized","metadata":{}},{"cell_type":"code","source":"result_state = inferencer.run(test_loader, max_epochs=1)\nresult_state.metrics","metadata":{"execution":{"iopub.status.busy":"2023-02-04T12:08:23.754558Z","iopub.execute_input":"2023-02-04T12:08:23.754945Z","iopub.status.idle":"2023-02-04T12:08:48.829192Z","shell.execute_reply.started":"2023-02-04T12:08:23.754885Z","shell.execute_reply":"2023-02-04T12:08:48.828116Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"{'Loss': 9.725091934204102,\n 'Accuracy': 0.1254,\n 'Precision': 0.023700517357652613,\n 'Recall': 0.1254,\n 'Top-5 Accuracy': 0.5139}"},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resized_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}