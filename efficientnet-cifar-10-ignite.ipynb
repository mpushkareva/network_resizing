{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Finetuning of ImageNet pretrained EfficientNet-B0 on CIFAR-10 with PyTorch Ignite\n\nRecently new ConvNets architectures have been proposed in [\"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks\"](https://arxiv.org/pdf/1905.11946.pdf) paper. According to the paper, model's compound scaling starting from a 'good' baseline provides an network that achieves  state-of-the-art on  ImageNet,  while  being 8.4x  smaller and 6.1x faster on inference than the best existing ConvNet.\n\n![efficientnets](https://raw.githubusercontent.com/pytorch/ignite/c22609796031f5831f054036895696c7e4df07ce/examples/notebooks/assets/efficientnets.png)\n\nFollowing the paper, EfficientNet-B0 model pretrained on ImageNet and finetuned on CIFAR10 dataset gives 98% test accuracy. Let's reproduce this result with Ignite. [Official implementation](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet) of EfficientNet uses Tensorflow, \nfor our case we will borrow the code from [katsura-jp/efficientnet-pytorch](https://github.com/katsura-jp/efficientnet-pytorch), \n[rwightman/pytorch-image-models](https://github.com/rwightman/pytorch-image-models) and [lukemelas/EfficientNet-PyTorch](https://github.com/lukemelas/EfficientNet-PyTorch/) repositories (kudos to authors!). We will download pretrained weights from [lukemelas/EfficientNet-PyTorch](https://github.com/lukemelas/EfficientNet-PyTorch/) repository.\n\n## Network architecture review\nThe architecture of EfficientNet-B0 is the following:\n```\n1 - Stem    - Conv3x3|BN|Swish\n\n2 - Blocks  - MBConv1, k3x3 \n            - MBConv6, k3x3 repeated 2 times\n            - MBConv6, k5x5 repeated 2 times\n            - MBConv6, k3x3 repeated 3 times\n            - MBConv6, k5x5 repeated 3 times\n            - MBConv6, k5x5 repeated 4 times\n            - MBConv6, k3x3\n                            totally 16 blocks\n\n3 - Head    - Conv1x1|BN|Swish \n            - Pooling\n            - Dropout\n            - FC\n```\n\nwhere \n```\nSwish(x) = x * sigmoid(x)\n```\nand `MBConvX` stands for mobile inverted bottleneck convolution, X - denotes expansion ratio:\n``` \nMBConv1 : \n  -> DepthwiseConv|BN|Swish -> SqueezeExcitation -> Conv|BN\n\nMBConv6 : \n  -> Conv|BN|Swish -> DepthwiseConv|BN|Swish -> SqueezeExcitation -> Conv|BN\n\nMBConv6+IdentitySkip : \n  -.-> Conv|BN|Swish -> DepthwiseConv|BN|Swish -> SqueezeExcitation -> Conv|BN-(+)->\n   \\___________________________________________________________________________/\n```","metadata":{}},{"cell_type":"code","source":"!pip install pytorch-ignite==0.2.* tensorboardX==1.6.*\n\nimport os\nimport numpy as np\nimport random\nimport torch\nimport ignite\n\nseed = 17\nrandom.seed(seed)\n_ = torch.manual_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2022-12-25T06:34:20.242688Z","iopub.execute_input":"2022-12-25T06:34:20.243197Z","iopub.status.idle":"2022-12-25T06:34:35.048703Z","shell.execute_reply.started":"2022-12-25T06:34:20.243093Z","shell.execute_reply":"2022-12-25T06:34:35.047693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model\n\n\nLet's define some helpful modules:\n- Flatten \n- Swish \n\nThe reason why Swish is not implemented in `torch.nn` can be found [here](https://github.com/pytorch/pytorch/pull/3182).\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass Swish(nn.Module):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n\n\nclass Flatten(nn.Module):\n    def forward(self, x):\n        return x.reshape(x.shape[0], -1)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:46.593240Z","iopub.execute_input":"2022-12-21T13:52:46.594132Z","iopub.status.idle":"2022-12-21T13:52:46.600045Z","shell.execute_reply.started":"2022-12-21T13:52:46.594094Z","shell.execute_reply":"2022-12-21T13:52:46.599191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's define `SqueezeExcitation` module","metadata":{}},{"cell_type":"code","source":"def targeted_dropout(a, w, training, gamma=1, alpha=0.5):\n    '''таргетированный дропаут\n    a - активности на выходе слоя, layer size: Batch * Cout * H * W\n    w - веса конволюционного слоя, conv weight size: Cout * Cin * k * k\n    gamma - доля выходных каналов, подверженных дропауту  (от 0 до 1)\n    alpha - величина отсева дропаута (от 0 до 1)\n    '''\n    # считаем норму весов для каждого выходного канала\n    with torch.no_grad():\n        norms = torch.norm(w.reshape(w.shape[0], -1), dim=1)\n        C_out = len(norms) # количество выходных каналов\n        values, indexes = torch.sort(norms)\n        changed = indexes[:int(gamma * C_out)]\n    #применяем дропаут только к выбранным gamma * C_out каналам\n    a[:, changed] = F.dropout2d(a[:, changed], alpha, training=training)\n    return a","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:46.601416Z","iopub.execute_input":"2022-12-21T13:52:46.602168Z","iopub.status.idle":"2022-12-21T13:52:46.621277Z","shell.execute_reply.started":"2022-12-21T13:52:46.602129Z","shell.execute_reply":"2022-12-21T13:52:46.620395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SqueezeExcitation(nn.Module):\n    \n    def __init__(self, inplanes, se_planes, gamma=1, alpha=0.5):\n        super(SqueezeExcitation, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, se_planes, \n                      kernel_size=1, stride=1, padding=0, bias=False)\n        self.conv2 = nn.Conv2d(se_planes, inplanes, \n                      kernel_size=1, stride=1, padding=0, bias=False)\n        self.swish = Swish()\n        self.sigmoid = nn.Sigmoid()\n        self.gamma = gamma\n        self.alpha = alpha\n\n    def forward(self, x):\n        x_se = torch.mean(x, dim=(-2, -1), keepdim=True)\n        x_se = self.conv1(x_se)\n        x_se = targeted_dropout(x_se, self.conv1.weight, self.training, self.gamma, self.alpha)\n        x_se = self.swish(x_se)\n        x_se = self.conv2(x_se)\n        x_se = targeted_dropout(x_se, self.conv2.weight, self.training, self.gamma, self.alpha)\n        x_se = self.sigmoid(x_se)\n        return x_se * x\n","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:46.623909Z","iopub.execute_input":"2022-12-21T13:52:46.624398Z","iopub.status.idle":"2022-12-21T13:52:46.634381Z","shell.execute_reply.started":"2022-12-21T13:52:46.624363Z","shell.execute_reply":"2022-12-21T13:52:46.633341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, we can define `MBConv`.\n\n**Note on implementation**: in Tensorflow (and PyTorch ports) convolutions use `SAME` padding option which in PyTorch requires\na specific padding computation and additional operation to apply. We will use built-in padding argument of the convolution.","metadata":{}},{"cell_type":"code","source":"class DepthWiseConv(nn.Module):\n    \n    def __init__(self, inplanes, expand_planes, kernel_size, stride, gamma=1, alpha=0.5):\n        super(DepthWiseConv, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.conv = nn.Conv2d(inplanes, expand_planes,\n                      kernel_size=kernel_size, stride=stride, \n                      padding=kernel_size // 2, groups=expand_planes,\n                      bias=False)\n        self.bn = nn.BatchNorm2d(expand_planes, momentum=0.01, eps=1e-3)\n        self.swish = Swish()\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = targeted_dropout(x, self.conv.weight, self.training, self.gamma, self.alpha)\n        x = self.swish(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:46.635877Z","iopub.execute_input":"2022-12-21T13:52:46.636284Z","iopub.status.idle":"2022-12-21T13:52:46.650007Z","shell.execute_reply.started":"2022-12-21T13:52:46.636250Z","shell.execute_reply":"2022-12-21T13:52:46.649052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ProjectConv(nn.Module):\n    \n    def __init__(self, expand_planes, planes, gamma=1, alpha=0.5):\n        super(ProjectConv, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.conv = nn.Conv2d(expand_planes, planes, \n                      kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn = nn.BatchNorm2d(planes, momentum=0.01, eps=1e-3)\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = targeted_dropout(x, self.conv.weight, self.training, self.gamma, self.alpha)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:46.651084Z","iopub.execute_input":"2022-12-21T13:52:46.652035Z","iopub.status.idle":"2022-12-21T13:52:46.661571Z","shell.execute_reply.started":"2022-12-21T13:52:46.652007Z","shell.execute_reply":"2022-12-21T13:52:46.660793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ExpansionConv(nn.Module):\n    \n    def __init__(self, inplanes, expand_planes, gamma=1, alpha=0.5):\n        super(ExpansionConv, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.conv = nn.Conv2d(inplanes, expand_planes, \n                      kernel_size=1, stride=1, padding=0, bias=False)\n        self.bn = nn.BatchNorm2d(expand_planes, momentum=0.01, eps=1e-3)\n        self.swish = Swish()\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = targeted_dropout(x, self.conv.weight, self.training, self.gamma, self.alpha)\n        x = self.swish(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:46.663481Z","iopub.execute_input":"2022-12-21T13:52:46.663783Z","iopub.status.idle":"2022-12-21T13:52:46.676011Z","shell.execute_reply.started":"2022-12-21T13:52:46.663759Z","shell.execute_reply":"2022-12-21T13:52:46.675074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.nn import functional as F\n\nclass MBConv(nn.Module):\n    def __init__(self, inplanes, planes, kernel_size, stride, \n                 expand_rate=1.0, se_rate=0.25, \n                 drop_connect_rate=0.2, \n                 gamma=1, \n                 alpha=0.5\n                ):\n        super(MBConv, self).__init__()\n\n        expand_planes = int(inplanes * expand_rate)\n        se_planes = max(1, int(inplanes * se_rate))\n\n        self.expansion_conv = None        \n        if expand_rate > 1.0:\n            self.expansion_conv = ExpansionConv(inplanes, expand_planes, gamma=gamma, alpha=alpha)\n            inplanes = expand_planes\n\n        self.depthwise_conv = DepthWiseConv(inplanes, expand_planes, kernel_size,\n                                            stride, gamma=gamma, alpha=alpha)\n\n        self.squeeze_excitation = SqueezeExcitation(expand_planes, se_planes, \n                                                    gamma=gamma, alpha=alpha)\n        \n        self.project_conv = ProjectConv(expand_planes, planes, gamma=gamma, alpha=alpha)\n\n        self.with_skip = stride == 1\n        self.drop_connect_rate = torch.tensor(drop_connect_rate, requires_grad=False)\n    \n    def _drop_connect(self, x):        \n        keep_prob = 1.0 - self.drop_connect_rate\n        drop_mask = torch.rand(x.shape[0], 1, 1, 1) + keep_prob\n        drop_mask = drop_mask.type_as(x)\n        drop_mask.floor_()\n        return drop_mask * x / keep_prob\n        \n    def forward(self, x):\n        z = x\n        if self.expansion_conv is not None:\n            x = self.expansion_conv(x)\n\n        x = self.depthwise_conv(x)\n        x = self.squeeze_excitation(x)\n        x = self.project_conv(x)\n        \n        # Add identity skip\n        if x.shape == z.shape and self.with_skip:            \n            if self.training and self.drop_connect_rate is not None:\n                self._drop_connect(x)\n            x += z\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:46.677162Z","iopub.execute_input":"2022-12-21T13:52:46.677422Z","iopub.status.idle":"2022-12-21T13:52:46.690547Z","shell.execute_reply.started":"2022-12-21T13:52:46.677399Z","shell.execute_reply":"2022-12-21T13:52:46.689699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Stem(nn.Module):\n    \n    def __init__(self, list_channels, gamma=1, alpha=0.5):\n        super(Stem, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.conv = nn.Conv2d(3, list_channels[0], kernel_size=3, stride=2, padding=1, bias=False)\n        self.bn = nn.BatchNorm2d(list_channels[0], momentum=0.01, eps=1e-3)\n        self.swish = Swish()\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = targeted_dropout(x, self.conv.weight, self.training, self.gamma, self.alpha)\n        x = self.swish(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:46.692386Z","iopub.execute_input":"2022-12-21T13:52:46.694241Z","iopub.status.idle":"2022-12-21T13:52:46.706391Z","shell.execute_reply.started":"2022-12-21T13:52:46.694205Z","shell.execute_reply":"2022-12-21T13:52:46.705467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HeadModule(nn.Module):\n    \n    def __init__(self, list_channels, num_classes, gamma=1, alpha=0.5):\n        super(HeadModule, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.conv = nn.Conv2d(list_channels[-2], list_channels[-1], \n                      kernel_size=1, bias=False)\n        self.bn = nn.BatchNorm2d(list_channels[-1], momentum=0.01, eps=1e-3)\n        self.swish = Swish()\n        self.avg = nn.AdaptiveAvgPool2d(1)\n        self.flatten = Flatten()\n        self.linear = nn.Linear(list_channels[-1], num_classes)\n\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x = targeted_dropout(x, self.conv.weight, self.training, self.gamma, self.alpha)\n        x = self.swish(x)\n        x = self.avg(x)\n        x = self.flatten(x)\n        x = self.linear(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:46.710772Z","iopub.execute_input":"2022-12-21T13:52:46.711033Z","iopub.status.idle":"2022-12-21T13:52:46.721648Z","shell.execute_reply.started":"2022-12-21T13:52:46.711009Z","shell.execute_reply":"2022-12-21T13:52:46.720783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And finally, we can implement generic `EfficientNet`:","metadata":{}},{"cell_type":"code","source":"from collections import OrderedDict\nimport math\n\n\ndef init_weights(module):    \n    if isinstance(module, nn.Conv2d):    \n        nn.init.kaiming_normal_(module.weight, a=0, mode='fan_out')\n    elif isinstance(module, nn.Linear):\n        init_range = 1.0 / math.sqrt(module.weight.shape[1])\n        nn.init.uniform_(module.weight, a=-init_range, b=init_range)\n        \n        \nclass EfficientNet(nn.Module):\n        \n    def _setup_repeats(self, num_repeats):\n        return int(math.ceil(self.depth_coefficient * num_repeats))\n    \n    def _setup_channels(self, num_channels):\n        num_channels *= self.width_coefficient\n        new_num_channels = math.floor(num_channels / self.divisor + 0.5) * self.divisor\n        new_num_channels = max(self.divisor, new_num_channels)\n        if new_num_channels < 0.9 * num_channels:\n            new_num_channels += self.divisor\n        return new_num_channels\n\n    def __init__(self, num_classes=10, \n                 width_coefficient=1.0,\n                 depth_coefficient=1.0,\n                 se_rate=0.25,\n                 gamma=1, alpha=0.5,\n                 drop_connect_rate=0.2):\n        super(EfficientNet, self).__init__()\n        \n        self.width_coefficient = width_coefficient\n        self.depth_coefficient = depth_coefficient\n        self.divisor = 8\n                \n        list_channels = [32, 16, 24, 40, 80, 112, 192, 320, 1280]\n        list_channels = [self._setup_channels(c) for c in list_channels]\n                \n        list_num_repeats = [1, 2, 2, 3, 3, 4, 1]\n        list_num_repeats = [self._setup_repeats(r) for r in list_num_repeats]        \n        \n        expand_rates = [1, 6, 6, 6, 6, 6, 6]\n        strides = [1, 2, 2, 2, 1, 2, 1]\n        kernel_sizes = [3, 3, 5, 3, 5, 5, 3]\n\n        # Define stem:\n        self.stem = Stem(list_channels, gamma=gamma, alpha=alpha)\n        \n        # Define MBConv blocks\n        blocks = []\n        counter = 0\n        num_blocks = sum(list_num_repeats)\n        for idx in range(7):\n            \n            num_channels = list_channels[idx]\n            next_num_channels = list_channels[idx + 1]\n            num_repeats = list_num_repeats[idx]\n            expand_rate = expand_rates[idx]\n            kernel_size = kernel_sizes[idx]\n            stride = strides[idx]\n            drop_rate = drop_connect_rate * counter / num_blocks\n            \n            name = \"MBConv{}_{}\".format(expand_rate, counter)\n            blocks.append((\n                name,\n                MBConv(num_channels, next_num_channels, \n                       kernel_size=kernel_size, stride=stride, expand_rate=expand_rate, \n                       se_rate=se_rate, drop_connect_rate=drop_rate, gamma=gamma, alpha=alpha)\n            ))\n            counter += 1\n            for i in range(1, num_repeats):                \n                name = \"MBConv{}_{}\".format(expand_rate, counter)\n                drop_rate = drop_connect_rate * counter / num_blocks                \n                blocks.append((\n                    name,\n                    MBConv(next_num_channels, next_num_channels, \n                           kernel_size=kernel_size, stride=1, expand_rate=expand_rate, \n                           se_rate=se_rate, drop_connect_rate=drop_rate, gamma=gamma, alpha=alpha)                                    \n                ))\n                counter += 1\n        \n        self.blocks = nn.Sequential(OrderedDict(blocks))\n        \n        # Define head\n        self.head = HeadModule(list_channels, num_classes, gamma=gamma, alpha=alpha)\n\n        self.apply(init_weights)\n        \n    def forward(self, x):\n        f = self.stem(x)\n        f = self.blocks(f)\n        y = self.head(f)\n        return y","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:46.724674Z","iopub.execute_input":"2022-12-21T13:52:46.724959Z","iopub.status.idle":"2022-12-21T13:52:46.743452Z","shell.execute_reply.started":"2022-12-21T13:52:46.724934Z","shell.execute_reply":"2022-12-21T13:52:46.742456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All EfficientNet models can be defined using the following parametrization:\n```\n# (width_coefficient, depth_coefficient, resolution, dropout_rate)\n'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n'efficientnet-b7': (2.0, 3.1, 600, 0.5),\n```    \nLet's define and train the third one: `EfficientNet-B0`","metadata":{}},{"cell_type":"code","source":"model = EfficientNet(num_classes=1000, \n                     width_coefficient=1.0, depth_coefficient=1.0, \n                    gamma=0.7, alpha=0.6)","metadata":{"execution":{"iopub.status.busy":"2022-12-25T12:18:28.475536Z","iopub.execute_input":"2022-12-25T12:18:28.476470Z","iopub.status.idle":"2022-12-25T12:18:28.551533Z","shell.execute_reply.started":"2022-12-25T12:18:28.476366Z","shell.execute_reply":"2022-12-25T12:18:28.550086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:46.865535Z","iopub.execute_input":"2022-12-21T13:52:46.865958Z","iopub.status.idle":"2022-12-21T13:52:46.879884Z","shell.execute_reply.started":"2022-12-21T13:52:46.865924Z","shell.execute_reply":"2022-12-21T13:52:46.878742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of parameters:","metadata":{}},{"cell_type":"code","source":"def print_num_params(model, display_all_modules=False):\n    total_num_params = 0\n    for n, p in model.named_parameters():\n        num_params = 1\n        for s in p.shape:\n            num_params *= s\n        if display_all_modules: print(\"{}: {}\".format(n, num_params))\n        total_num_params += num_params\n    print(\"-\" * 50)\n    print(\"Total number of parameters: {:.2e}\".format(total_num_params))\n    \n\nprint_num_params(model)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:46.881513Z","iopub.execute_input":"2022-12-21T13:52:46.882123Z","iopub.status.idle":"2022-12-21T13:52:46.890186Z","shell.execute_reply.started":"2022-12-21T13:52:46.882090Z","shell.execute_reply":"2022-12-21T13:52:46.888983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's compare the number of parameters with some of ResNets:","metadata":{}},{"cell_type":"code","source":"from torchvision.models.resnet import resnet18, resnet34, resnet50\n","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:46.892055Z","iopub.execute_input":"2022-12-21T13:52:46.893143Z","iopub.status.idle":"2022-12-21T13:52:47.104652Z","shell.execute_reply.started":"2022-12-21T13:52:46.893066Z","shell.execute_reply":"2022-12-21T13:52:47.103786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_num_params(resnet18(pretrained=False, num_classes=10))\nprint_num_params(resnet34(pretrained=False, num_classes=10))\nprint_num_params(resnet50(pretrained=False, num_classes=10))","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:47.106358Z","iopub.execute_input":"2022-12-21T13:52:47.107218Z","iopub.status.idle":"2022-12-21T13:52:48.227628Z","shell.execute_reply.started":"2022-12-21T13:52:47.107182Z","shell.execute_reply":"2022-12-21T13:52:48.226571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model's graph with Tensorboard\n\nWe can optionally inspect model's graph with the code below. For that we need to install\n`tensorboardX` package.\nOtherwise go directly to the next section.","metadata":{}},{"cell_type":"code","source":"from tensorboardX.pytorch_graph import graph\n\nimport random\nfrom IPython.display import clear_output, Image, display, HTML\n\n\ndef show_graph(graph_def):\n    \"\"\"Visualize TensorFlow graph.\"\"\"\n    if hasattr(graph_def, 'as_graph_def'):\n        graph_def = graph_def.as_graph_def()\n    strip_def = graph_def\n    code = \"\"\"\n        <script src=\"//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js\"></script>\n        <script>\n          function load() {{\n            document.getElementById(\"{id}\").pbtxt = {data};\n          }}\n        </script>\n        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n        <div style=\"height:600px\">\n          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n        </div>\n    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(random.randint(0, 1000)))\n\n    iframe = \"\"\"\n        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n    \"\"\".format(code.replace('\"', '&quot;'))\n    display(HTML(iframe))","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:48.229176Z","iopub.execute_input":"2022-12-21T13:52:48.229832Z","iopub.status.idle":"2022-12-21T13:52:48.359886Z","shell.execute_reply.started":"2022-12-21T13:52:48.229794Z","shell.execute_reply":"2022-12-21T13:52:48.358990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load pretrained weights\n\nLet's load pretrained weights and check the model on a single image.","metadata":{}},{"cell_type":"code","source":"!wget http://storage.googleapis.com/public-models/efficientnet-b0-08094119.pth","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:48.361091Z","iopub.execute_input":"2022-12-21T13:52:48.361447Z","iopub.status.idle":"2022-12-21T13:52:49.845145Z","shell.execute_reply.started":"2022-12-21T13:52:48.361394Z","shell.execute_reply":"2022-12-21T13:52:49.843786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(model.state_dict().keys())","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:49.847013Z","iopub.execute_input":"2022-12-21T13:52:49.848768Z","iopub.status.idle":"2022-12-21T13:52:49.861471Z","shell.execute_reply.started":"2022-12-21T13:52:49.848722Z","shell.execute_reply":"2022-12-21T13:52:49.860479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import OrderedDict\n\nmodel_state = torch.load(\"efficientnet-b0-08094119.pth\")\nmodel_state2 = [k for k in model_state.keys() if not ('bias' in k and 'bn' not in k and 'fc' not in k)]\n# A basic remapping is required\nmapping = {\n    k: v for k, v in zip(model_state2, model.state_dict().keys())\n                         }\nmapped_model_state = OrderedDict([\n    (mapping[k], model_state[k]) for k in model_state2\n])\n\nmodel.load_state_dict(mapped_model_state, strict=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:49.863718Z","iopub.execute_input":"2022-12-21T13:52:49.864306Z","iopub.status.idle":"2022-12-21T13:52:49.934260Z","shell.execute_reply.started":"2022-12-21T13:52:49.864269Z","shell.execute_reply":"2022-12-21T13:52:49.933203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/lukemelas/EfficientNet-PyTorch/master/examples/simple/img.jpg -O/tmp/giant_panda.jpg\n!wget https://raw.githubusercontent.com/lukemelas/EfficientNet-PyTorch/master/examples/simple/labels_map.txt -O/tmp/labels_map.txt","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:49.935959Z","iopub.execute_input":"2022-12-21T13:52:49.936312Z","iopub.status.idle":"2022-12-21T13:52:52.375041Z","shell.execute_reply.started":"2022-12-21T13:52:49.936277Z","shell.execute_reply":"2022-12-21T13:52:52.373847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:52.376974Z","iopub.execute_input":"2022-12-21T13:52:52.377276Z","iopub.status.idle":"2022-12-21T13:52:52.384146Z","shell.execute_reply.started":"2022-12-21T13:52:52.377245Z","shell.execute_reply":"2022-12-21T13:52:52.382981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\nwith open(\"/tmp/labels_map.txt\", \"r\") as h:\n    labels = json.load(h)\n\nfrom PIL import Image\nimport torchvision.transforms as transforms\n\n\nimg = Image.open(\"/tmp/giant_panda.jpg\")\n# Preprocess image\ntfms = transforms.Compose([transforms.Resize(224),\n                           transforms.ToTensor(),\n                           transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\nx = tfms(img).unsqueeze(0)\n_ = plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:52.385962Z","iopub.execute_input":"2022-12-21T13:52:52.386368Z","iopub.status.idle":"2022-12-21T13:52:52.726286Z","shell.execute_reply.started":"2022-12-21T13:52:52.386286Z","shell.execute_reply":"2022-12-21T13:52:52.724652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classify\nmodel.eval()\nwith torch.no_grad():\n    y_pred = model(x)\n\n# Print predictions\nprint('-----')\nfor idx in torch.topk(y_pred, k=5)[1].squeeze(0).tolist():\n    prob = torch.softmax(y_pred, dim=1)[0, idx].item()\n    print('{label:<75} ({p:.2f}%)'.format(label=labels[str(idx)], p=prob*100))","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:52.727333Z","iopub.execute_input":"2022-12-21T13:52:52.727887Z","iopub.status.idle":"2022-12-21T13:52:52.932160Z","shell.execute_reply.started":"2022-12-21T13:52:52.727848Z","shell.execute_reply":"2022-12-21T13:52:52.931149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataflow\n\nLet's setup the dataflow:\n- load CIFAR10 train and test datasets\n- setup train/test image transforms\n- setup train/test data loaders\n\nAccording to the paper authors borrowed training settings from other publications and the dataflow for CIFAR10 is the following:\n\n- input images to the network during training are resized to 224x224\n- horizontally flipped randomly and augmented using cutout.\n- each mini-batch contained 256 examples\n","metadata":{}},{"cell_type":"code","source":"from torchvision.datasets.cifar import CIFAR100, CIFAR10\nfrom torchvision.transforms import Compose, RandomCrop, Pad, RandomHorizontalFlip, Resize, RandomAffine\nfrom torchvision.transforms import ToTensor, Normalize\n\nfrom torch.utils.data import Subset\nimport torchvision.utils as vutils","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:52.933891Z","iopub.execute_input":"2022-12-21T13:52:52.934268Z","iopub.status.idle":"2022-12-21T13:52:52.939849Z","shell.execute_reply.started":"2022-12-21T13:52:52.934230Z","shell.execute_reply":"2022-12-21T13:52:52.938841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input\n!tar -zxvf ../input/cifar10-python/cifar-10-python.tar.gz\n# /input/cifar-10-python.tar.gz","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:52.941118Z","iopub.execute_input":"2022-12-21T13:52:52.941947Z","iopub.status.idle":"2022-12-21T13:52:58.710544Z","shell.execute_reply.started":"2022-12-21T13:52:52.941901Z","shell.execute_reply":"2022-12-21T13:52:58.709361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL.Image import BICUBIC\n\npath = \".\"\nimage_size = 224\n\ntrain_transform = Compose([\n    Resize(image_size, BICUBIC),\n    RandomAffine(degrees=2, translate=(0.02, 0.02), scale=(0.98, 1.02), shear=2, fillcolor=(124,117,104)),\n    RandomHorizontalFlip(),\n    ToTensor(),\n    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntest_transform = Compose([\n    Resize(image_size, BICUBIC),    \n    ToTensor(),\n    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\ntrain_dataset = CIFAR10(root=path, train=True, transform=train_transform, download=False)\ntest_dataset = CIFAR10(root=path, train=False, transform=test_transform, download=False)\n\ntrain_eval_indices = [random.randint(0, len(train_dataset) - 1) for i in range(len(test_dataset))]\ntrain_eval_dataset = Subset(train_dataset, train_eval_indices)\n\nlen(train_dataset), len(test_dataset), len(train_eval_dataset)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:58.712640Z","iopub.execute_input":"2022-12-21T13:52:58.713271Z","iopub.status.idle":"2022-12-21T13:52:59.773642Z","shell.execute_reply.started":"2022-12-21T13:52:58.713227Z","shell.execute_reply":"2022-12-21T13:52:59.772580Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\nbatch_size = 125\nnum_workers = 2\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, \n                          shuffle=True, drop_last=True, pin_memory=True)\n\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers, \n                         shuffle=False, drop_last=False, pin_memory=True)\n\neval_train_loader = DataLoader(train_eval_dataset, batch_size=batch_size, num_workers=num_workers, \n                               shuffle=False, drop_last=False, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:59.780430Z","iopub.execute_input":"2022-12-21T13:52:59.780738Z","iopub.status.idle":"2022-12-21T13:52:59.787738Z","shell.execute_reply.started":"2022-12-21T13:52:59.780711Z","shell.execute_reply":"2022-12-21T13:52:59.786038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot some training images\nbatch = next(iter(train_loader))\n\nplt.figure(figsize=(16, 8))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\n_ = plt.imshow( \n    vutils.make_grid(batch[0][:16], padding=2, normalize=True).cpu().numpy().transpose((1, 2, 0))\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:52:59.789382Z","iopub.execute_input":"2022-12-21T13:52:59.790056Z","iopub.status.idle":"2022-12-21T13:53:05.409722Z","shell.execute_reply.started":"2022-12-21T13:52:59.790016Z","shell.execute_reply":"2022-12-21T13:53:05.408704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classify prior to fine tunning\nmodel.eval()\nwith torch.no_grad():\n    y_pred = model(batch[0][:1])\n\n# Print predictions\nprint('-----')\nfor idx in torch.topk(y_pred, k=9)[1].squeeze(0).tolist():\n    prob = torch.softmax(y_pred, dim=1)[0, idx].item()\n    print('{label:<75} ({p:.2f}%)'.format(label=labels[str(idx)], p=prob*100))","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:05.411508Z","iopub.execute_input":"2022-12-21T13:53:05.412293Z","iopub.status.idle":"2022-12-21T13:53:05.494725Z","shell.execute_reply.started":"2022-12-21T13:53:05.412251Z","shell.execute_reply":"2022-12-21T13:53:05.493541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch = None\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:05.496218Z","iopub.execute_input":"2022-12-21T13:53:05.497003Z","iopub.status.idle":"2022-12-21T13:53:05.503071Z","shell.execute_reply.started":"2022-12-21T13:53:05.496961Z","shell.execute_reply":"2022-12-21T13:53:05.501041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finetunning model","metadata":{}},{"cell_type":"markdown","source":"As we are interested to finetune the model to CIFAR-10, we will replace the classification fully-connected layer (ImageNet-1000 vs CIFAR-10).","metadata":{}},{"cell_type":"code","source":"# model.head[6].in_features, model.head[6].out_features\nmodel.head.linear.in_features, model.head.linear.out_features","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:05.504417Z","iopub.execute_input":"2022-12-21T13:53:05.504730Z","iopub.status.idle":"2022-12-21T13:53:05.515373Z","shell.execute_reply.started":"2022-12-21T13:53:05.504693Z","shell.execute_reply":"2022-12-21T13:53:05.514189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.head[6] = nn.Linear(1280, 10)\nmodel.head.linear = nn.Linear(1280, 10)\nc10classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:05.516876Z","iopub.execute_input":"2022-12-21T13:53:05.517770Z","iopub.status.idle":"2022-12-21T13:53:05.524708Z","shell.execute_reply.started":"2022-12-21T13:53:05.517733Z","shell.execute_reply":"2022-12-21T13:53:05.523974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.head[6].in_features, model.head[6].out_features\n\nmodel.head.linear.in_features, model.head.linear.out_features","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:05.525873Z","iopub.execute_input":"2022-12-21T13:53:05.526813Z","iopub.status.idle":"2022-12-21T13:53:05.536333Z","shell.execute_reply.started":"2022-12-21T13:53:05.526778Z","shell.execute_reply":"2022-12-21T13:53:05.535235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will finetune the model on GPU with AMP fp32/fp16 using nvidia/apex package.","metadata":{}},{"cell_type":"code","source":"assert torch.cuda.is_available()\nassert torch.backends.cudnn.enabled, \"NVIDIA/Apex:Amp requires cudnn backend to be enabled.\"\ntorch.backends.cudnn.benchmark = True\n\ndevice = \"cuda\"","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:05.538040Z","iopub.execute_input":"2022-12-21T13:53:05.538482Z","iopub.status.idle":"2022-12-21T13:53:05.546198Z","shell.execute_reply.started":"2022-12-21T13:53:05.538446Z","shell.execute_reply":"2022-12-21T13:53:05.545231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:05.547898Z","iopub.execute_input":"2022-12-21T13:53:05.548269Z","iopub.status.idle":"2022-12-21T13:53:05.573715Z","shell.execute_reply.started":"2022-12-21T13:53:05.548236Z","shell.execute_reply":"2022-12-21T13:53:05.572849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's setup cross-entropy as criterion and SGD as optimizer.\n\nWe will split model parameters into 2 groups: \n\n    1) feature extractor (pretrained weights)\n    2) classifier (random weights)\n\nand define different learning rates for these groups (via learning rate scheduler).","metadata":{}},{"cell_type":"code","source":"from itertools import chain\n\nimport torch.optim as optim\nimport torch.nn.functional as F\n\ncriterion = nn.CrossEntropyLoss()\nlr = 0.01\n\noptimizer = optim.SGD([\n    {\n        \"params\": chain(model.stem.parameters(), model.blocks.parameters()),\n        \"lr\": lr * 0.4, # 0.8ß\n    },\n    {\n#         \"params\": model.head[:6].parameters(),\n        \"params\": model.head.conv.parameters(),\n        \"lr\": lr * 0.6, # 0.9\n    }, \n    {\n        \"params\": model.head.bn.parameters(),\n        \"lr\": lr * 0.7, # 0.9\n    },  \n    {\n#         \"params\": model.head[6].parameters(), \n        \"params\": model.head.linear.parameters(),\n        \"lr\": lr\n    }], \n    momentum=0.9, weight_decay=1e-3, nesterov=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:05.575232Z","iopub.execute_input":"2022-12-21T13:53:05.575561Z","iopub.status.idle":"2022-12-21T13:53:05.584297Z","shell.execute_reply.started":"2022-12-21T13:53:05.575528Z","shell.execute_reply":"2022-12-21T13:53:05.583239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.optim.lr_scheduler import ExponentialLR\nlr_scheduler = ExponentialLR(optimizer, gamma=0.975)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:05.585952Z","iopub.execute_input":"2022-12-21T13:53:05.586767Z","iopub.status.idle":"2022-12-21T13:53:05.593353Z","shell.execute_reply.started":"2022-12-21T13:53:05.586731Z","shell.execute_reply":"2022-12-21T13:53:05.592719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Next, let's define a single iteration function `update_fn`. This function is then used by `ignite.engine.Engine` to update model while running over the input data.","metadata":{}},{"cell_type":"code","source":"from ignite.utils import convert_tensor\nscaler = torch.cuda.amp.GradScaler()\ndef update_fn(engine, batch):\n    model.train()\n\n    x = convert_tensor(batch[0], device=device, non_blocking=True)\n    y = convert_tensor(batch[1], device=device, non_blocking=True)\n    \n    optimizer.zero_grad()\n    \n    with torch.cuda.amp.autocast():\n        y_pred = model(x)\n        loss = criterion(y_pred, y)    \n \n    scaler.scale(loss).backward()\n    scaler.step(optimizer)\n    scaler.update()\n\n    return {\n        \"batchloss\": loss.item(),\n    }    ","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:05.596618Z","iopub.execute_input":"2022-12-21T13:53:05.596921Z","iopub.status.idle":"2022-12-21T13:53:05.606922Z","shell.execute_reply.started":"2022-12-21T13:53:05.596897Z","shell.execute_reply":"2022-12-21T13:53:05.605951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's check `update_fn`","metadata":{}},{"cell_type":"code","source":"batch = next(iter(train_loader))\n\nres = update_fn(engine=None, batch=batch)\n\nbatch = None\ntorch.cuda.empty_cache()\n\nres","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:05.609460Z","iopub.execute_input":"2022-12-21T13:53:05.610694Z","iopub.status.idle":"2022-12-21T13:53:15.099745Z","shell.execute_reply.started":"2022-12-21T13:53:05.610630Z","shell.execute_reply":"2022-12-21T13:53:15.098641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's define a trainer and add some practical handlers:\n- log to tensorboard: losses, metrics, lr\n- progress bar\n- models/optimizers checkpointing","metadata":{}},{"cell_type":"code","source":"from ignite.engine import Engine, Events, create_supervised_evaluator\nfrom ignite.metrics import RunningAverage, Accuracy, Precision, Recall, Loss, TopKCategoricalAccuracy\n\nfrom ignite.contrib.handlers import TensorboardLogger\nfrom ignite.contrib.handlers.tensorboard_logger import OutputHandler, OptimizerParamsHandler","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:15.101800Z","iopub.execute_input":"2022-12-21T13:53:15.102189Z","iopub.status.idle":"2022-12-21T13:53:15.115802Z","shell.execute_reply.started":"2022-12-21T13:53:15.102146Z","shell.execute_reply":"2022-12-21T13:53:15.114600Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Engine(update_fn)\n\ndef output_transform(out):\n    return out['batchloss']\n\nRunningAverage(output_transform=output_transform).attach(trainer, \"batchloss\")","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:15.117244Z","iopub.execute_input":"2022-12-21T13:53:15.117750Z","iopub.status.idle":"2022-12-21T13:53:15.129622Z","shell.execute_reply.started":"2022-12-21T13:53:15.117712Z","shell.execute_reply":"2022-12-21T13:53:15.128718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\n\nexp_name = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nlog_path = f\"/tmp/finetune_efficientnet_cifar10/{exp_name}\"\ntb_logger = TensorboardLogger(log_dir=log_path)\n\ntb_logger.attach(trainer, \n                 log_handler=OutputHandler('training', ['batchloss', ]), \n                 event_name=Events.ITERATION_COMPLETED)\n\nprint(\"Experiment name: \", exp_name)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:15.131117Z","iopub.execute_input":"2022-12-21T13:53:15.131585Z","iopub.status.idle":"2022-12-21T13:53:15.154140Z","shell.execute_reply.started":"2022-12-21T13:53:15.131547Z","shell.execute_reply":"2022-12-21T13:53:15.153178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's setup learning rate scheduling:","metadata":{}},{"cell_type":"code","source":"trainer.add_event_handler(Events.EPOCH_COMPLETED, lambda engine: lr_scheduler.step())\n\n# Log optimizer parameters\ntb_logger.attach(trainer,\n                 log_handler=OptimizerParamsHandler(optimizer, \"lr\"), \n                 event_name=Events.EPOCH_STARTED)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:15.156656Z","iopub.execute_input":"2022-12-21T13:53:15.156984Z","iopub.status.idle":"2022-12-21T13:53:15.161876Z","shell.execute_reply.started":"2022-12-21T13:53:15.156959Z","shell.execute_reply":"2022-12-21T13:53:15.160686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ignite.contrib.handlers import ProgressBar\n\n# Iteration-wise progress bar\nProgressBar(bar_format=\"\").attach(trainer, metric_names=['batchloss',])\n\n# Epoch-wise progress bar with display of training losses\nProgressBar(persist=True, bar_format=\"\").attach(trainer, metric_names=['batchloss',],\n                                                event_name=Events.EPOCH_STARTED,\n                                                closing_event_name=Events.COMPLETED)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:15.163466Z","iopub.execute_input":"2022-12-21T13:53:15.163827Z","iopub.status.idle":"2022-12-21T13:53:15.173273Z","shell.execute_reply.started":"2022-12-21T13:53:15.163792Z","shell.execute_reply":"2022-12-21T13:53:15.172339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's create two evaluators to compute metrics on train/test images and log them to Tensorboard:","metadata":{}},{"cell_type":"code","source":"metrics = {\n    'Loss': Loss(criterion),\n    'Accuracy': Accuracy(),\n    'Precision': Precision(average=True),\n    'Recall': Recall(average=True),\n    'Top-5 Accuracy': TopKCategoricalAccuracy(k=5)\n}\n\nevaluator = create_supervised_evaluator(model, metrics=metrics, device=device, non_blocking=True)\ntrain_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device, non_blocking=True)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:15.174840Z","iopub.execute_input":"2022-12-21T13:53:15.175183Z","iopub.status.idle":"2022-12-21T13:53:15.196075Z","shell.execute_reply.started":"2022-12-21T13:53:15.175150Z","shell.execute_reply":"2022-12-21T13:53:15.195236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ignite.contrib.handlers import CustomPeriodicEvent\n\ncpe = CustomPeriodicEvent(n_epochs=3)\ncpe.attach(trainer)\n\n\ndef run_evaluation(engine):\n    train_evaluator.run(eval_train_loader)\n    evaluator.run(test_loader)\n\n\ntrainer.add_event_handler(cpe.Events.EPOCHS_3_STARTED, run_evaluation)\ntrainer.add_event_handler(Events.COMPLETED, run_evaluation)\n\n\n# Log train eval metrics:\ntb_logger.attach(train_evaluator,\n                 log_handler=OutputHandler(tag=\"training\",\n                                           metric_names=list(metrics.keys()),\n                                           another_engine=trainer),\n                 event_name=Events.EPOCH_COMPLETED)\n\n# Log val metrics:\ntb_logger.attach(evaluator,\n                 log_handler=OutputHandler(tag=\"test\",\n                                           metric_names=list(metrics.keys()),\n                                           another_engine=trainer),\n                 event_name=Events.EPOCH_COMPLETED)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:15.198805Z","iopub.execute_input":"2022-12-21T13:53:15.199054Z","iopub.status.idle":"2022-12-21T13:53:15.208728Z","shell.execute_reply.started":"2022-12-21T13:53:15.199031Z","shell.execute_reply":"2022-12-21T13:53:15.207831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's setup the best model checkpointing, early stopping:","metadata":{}},{"cell_type":"code","source":"import logging\n\n# Setup engine &  logger\ndef setup_logger(logger):\n    handler = logging.StreamHandler()\n    formatter = logging.Formatter(\"%(asctime)s %(name)-12s %(levelname)-8s %(message)s\")\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n    logger.setLevel(logging.INFO)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:15.210135Z","iopub.execute_input":"2022-12-21T13:53:15.210946Z","iopub.status.idle":"2022-12-21T13:53:15.218581Z","shell.execute_reply.started":"2022-12-21T13:53:15.210903Z","shell.execute_reply":"2022-12-21T13:53:15.217713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from ignite.handlers import ModelCheckpoint, EarlyStopping, TerminateOnNan\n\ntrainer.add_event_handler(Events.ITERATION_COMPLETED, TerminateOnNan())\n\n# Store the best model\ndef default_score_fn(engine):\n    score = engine.state.metrics['Accuracy']\n    return score\n\nbest_model_handler = ModelCheckpoint(dirname=log_path,\n                                     filename_prefix=\"best\",\n                                     n_saved=3,\n                                     score_name=\"test_acc\",\n                                     score_function=default_score_fn)\nevaluator.add_event_handler(Events.COMPLETED, best_model_handler, {'model': model, })\n\n# Add early stopping\nes_patience = 10\nes_handler = EarlyStopping(patience=es_patience, score_function=default_score_fn, trainer=trainer)\nevaluator.add_event_handler(Events.COMPLETED, es_handler)\nsetup_logger(es_handler._logger)\n\n# Clear cuda cache between training/testing\ndef empty_cuda_cache(engine):\n    torch.cuda.empty_cache()\n    import gc\n    \n    gc.collect()\n\ntrainer.add_event_handler(Events.EPOCH_COMPLETED, empty_cuda_cache)\nevaluator.add_event_handler(Events.COMPLETED, empty_cuda_cache)\ntrain_evaluator.add_event_handler(Events.COMPLETED, empty_cuda_cache)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:15.219948Z","iopub.execute_input":"2022-12-21T13:53:15.220854Z","iopub.status.idle":"2022-12-21T13:53:15.237041Z","shell.execute_reply.started":"2022-12-21T13:53:15.220820Z","shell.execute_reply":"2022-12-21T13:53:15.236034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 100 \n \ntrainer.run(train_loader, max_epochs=num_epochs) ","metadata":{"execution":{"iopub.status.busy":"2022-12-21T13:53:15.238415Z","iopub.execute_input":"2022-12-21T13:53:15.238953Z","iopub.status.idle":"2022-12-21T14:04:10.939351Z","shell.execute_reply.started":"2022-12-21T13:53:15.238910Z","shell.execute_reply":"2022-12-21T14:04:10.937671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finetunning results:\n\n- Test dataset:","metadata":{}},{"cell_type":"code","source":"evaluator.state.metrics","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:04:10.941144Z","iopub.status.idle":"2022-12-21T14:04:10.942017Z","shell.execute_reply.started":"2022-12-21T14:04:10.941636Z","shell.execute_reply":"2022-12-21T14:04:10.941690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- Training subset:","metadata":{}},{"cell_type":"code","source":"train_evaluator.state.metrics","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:04:10.943485Z","iopub.status.idle":"2022-12-21T14:04:10.944277Z","shell.execute_reply.started":"2022-12-21T14:04:10.944010Z","shell.execute_reply":"2022-12-21T14:04:10.944039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Obviously, our training settings is not the optimal one and the delta between our result and the paper's one is about 5%.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference\n\nLet's load the best model and recompute evaluation metrics on test dataset with a very basic Test-Time-Augmentation to boost the performances.\n","metadata":{}},{"cell_type":"markdown","source":"## Вот тут","metadata":{}},{"cell_type":"code","source":"# Find the last checkpoint\n!ls {log_path}\ncheckpoints = next(os.walk(log_path))[2]\ncheckpoints = sorted(filter(lambda f: f.endswith(\".pth\"), checkpoints))\nscores = [c[22:28] for c in checkpoints]\nbest_epoch = np.argmax(scores)\nprint(best_epoch, scores)\nif not checkpoints:\n    print('No weight files in {}'.format(log_path))\nelse:\n    model_path = f'efficientNet_cifar10_{scores[best_epoch]}.pth'\n    !cp {os.path.join(log_path, checkpoints[best_epoch])} {model_path}\n\n    \nprint(model_path)\n!rm {log_path}/*","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:04:10.945645Z","iopub.status.idle":"2022-12-21T14:04:10.946496Z","shell.execute_reply.started":"2022-12-21T14:04:10.946225Z","shell.execute_reply":"2022-12-21T14:04:10.946252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_model = EfficientNet()\nbest_model.load_state_dict(torch.load(model_path))","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:04:10.947858Z","iopub.status.idle":"2022-12-21T14:04:10.948642Z","shell.execute_reply.started":"2022-12-21T14:04:10.948307Z","shell.execute_reply":"2022-12-21T14:04:10.948394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics = {\n    'Accuracy': Accuracy(),\n    'Precision': Precision(average=True),\n    'Recall': Recall(average=True),\n}\n\nall_pred = np.empty((0, 10), float)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:04:10.949994Z","iopub.status.idle":"2022-12-21T14:04:10.950762Z","shell.execute_reply.started":"2022-12-21T14:04:10.950439Z","shell.execute_reply":"2022-12-21T14:04:10.950474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_update_with_tta(engine, batch):\n    global all_pred\n    best_model.eval()\n    with torch.no_grad():\n        x, y = batch        \n        # Let's compute final prediction as a mean of predictions on x and flipped x\n        y_pred1 = best_model(x)\n        y_pred2 = best_model(x.flip(dims=(-1, )))\n        y_pred = 0.5 * (y_pred1 + y_pred2)\n        # calc softmax for submission\n        curr_pred = (0.5 * (F.softmax(y_pred1, dim=-1) + F.softmax(y_pred1, dim=-1))).data.cpu().numpy()\n        all_pred = np.vstack([all_pred, curr_pred])\n\n        return y_pred, y\n\ninferencer = Engine(inference_update_with_tta)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:04:10.952154Z","iopub.status.idle":"2022-12-21T14:04:10.953018Z","shell.execute_reply.started":"2022-12-21T14:04:10.952765Z","shell.execute_reply":"2022-12-21T14:04:10.952791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, metric in metrics.items():\n    metric.attach(inferencer, name)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:04:10.954420Z","iopub.status.idle":"2022-12-21T14:04:10.955201Z","shell.execute_reply.started":"2022-12-21T14:04:10.954950Z","shell.execute_reply":"2022-12-21T14:04:10.954976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ProgressBar(desc=\"Inference\").attach(inferencer)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:04:10.956586Z","iopub.status.idle":"2022-12-21T14:04:10.957401Z","shell.execute_reply.started":"2022-12-21T14:04:10.957142Z","shell.execute_reply":"2022-12-21T14:04:10.957169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_state = inferencer.run(test_loader, max_epochs=1)\n","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:04:10.958779Z","iopub.status.idle":"2022-12-21T14:04:10.959566Z","shell.execute_reply.started":"2022-12-21T14:04:10.959217Z","shell.execute_reply":"2022-12-21T14:04:10.959303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_state.metrics","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:04:10.960927Z","iopub.status.idle":"2022-12-21T14:04:10.961724Z","shell.execute_reply.started":"2022-12-21T14:04:10.961372Z","shell.execute_reply":"2022-12-21T14:04:10.961395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot some training images\nbatch = next(iter(test_loader))\n\nplt.figure(figsize=(16, 8))\nplt.axis(\"off\")\nplt.title(\"Training Images\")\n_ = plt.imshow( \n    vutils.make_grid(batch[0][:16], padding=2, normalize=True).cpu().numpy().transpose((1, 2, 0))\n)","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:04:10.963063Z","iopub.status.idle":"2022-12-21T14:04:10.963854Z","shell.execute_reply.started":"2022-12-21T14:04:10.963511Z","shell.execute_reply":"2022-12-21T14:04:10.963537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Classify\nbest_model.eval()\nwith torch.no_grad():\n    y_pred = best_model(batch[0][:1])\n\n# Print predictions\nprint('-----')\nfor idx in torch.topk(y_pred, k=9)[1].squeeze(0).tolist():\n    prob = torch.softmax(y_pred, dim=1)[0, idx].item()\n    print('{label:<75} ({p:.2f}%)'.format(label=c10classes[idx], p=prob*100))","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:04:10.965176Z","iopub.status.idle":"2022-12-21T14:04:10.965965Z","shell.execute_reply.started":"2022-12-21T14:04:10.965632Z","shell.execute_reply":"2022-12-21T14:04:10.965657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally, we obtain similar scores:","metadata":{}},{"cell_type":"code","source":"print(all_pred.shape)\nimport pandas as pd\nsub = pd.DataFrame(all_pred, columns=c10classes)\nsub.to_csv('efficientNetB0.csv', index_label='id')\nsub.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:04:10.967355Z","iopub.status.idle":"2022-12-21T14:04:10.968160Z","shell.execute_reply.started":"2022-12-21T14:04:10.967824Z","shell.execute_reply":"2022-12-21T14:04:10.967849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# clean up folders\n!rm -rf cifar* apex /tmp/*\n!ls *","metadata":{"execution":{"iopub.status.busy":"2022-12-21T14:04:10.969525Z","iopub.status.idle":"2022-12-21T14:04:10.970306Z","shell.execute_reply.started":"2022-12-21T14:04:10.969979Z","shell.execute_reply":"2022-12-21T14:04:10.970003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}